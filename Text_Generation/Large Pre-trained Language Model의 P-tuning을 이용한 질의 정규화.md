#### 논문 - Large Pre-trained Language Model의 P-tuning을 이용한 질의 정규화

- 저자: 서수빈, 인수교, 박진성, 남경민, 김현욱, 문기윤, 황원요, 김경덕, 강인호 (네이버)
- [논문 링크](https://koreascience.kr/article/CFKO202130060684827.pdf)
------------------------------------------------
- **목적**
  - 초거대 언어모델(large language model) 등장 전, 각 task에 맞는 데이터를 바탕으로 처음부터 학습하거나 이미 학습된 모델을 각 task에 맞게 추가 학습(fine-tuning)시켜 해결하였음
  - 초거대 언어모델이 등장하고 나서는 재학습에 드는 비용이 매우 커지는 문제, 태스크별 학습된 모델을 운용하는 문제가 발생하였음
    - 이를 해결하기 위해 few shot 학습법 등장
    - few shot 학습법도 한계가 존재햇으며 이를 해결하기 위해 새로운 신경망을 추가하여 학습하는 방법이 제시되었음
  - 초거대 언어모델은 사용자의 질의에 대한 응답을 생성하는 대화 모델에도 쉽게 적용 가능
    - 이전의 사용자와 대화 모델 간의 문맥에 대한 이해가 필요함
    - 이 때문에 문맥에 대한 사용자의 최종 의도를 파악하여 한 문장으로 명확히 표현하는 정규화 문제가 중요하게 고려되어야 하는 문제가 되었음
  - 본논문에선 초거대 언어모델의 새로운 데이터 기반 추가 학습 방법중 하나인 P-tuning 방법론을 사용하여 개선 사항을 제시
    - P-tuning을 활용한 실험을 통해 질의 정규화 문제에서 기존 고정 퓨샷 학습법 대비 정확도 향상을 보임
    - P-tuning에서 few-shot 유무에 따른 성능 변화와 epoch, 크기별 성능 탐색을 통해 최적의 프롬프트를 찾아 성능을 극대화함
    - 본 논문에서는 생성 문제에 대해 적용함으로써 생성 문제에 대해서도 P-tuning이 잘 동작함을 보였음  
------------------------------------------------
- **방법** 
  - 질의 정규화
    - 대화에서의 문맥을 바탕으로 최종 의도를 파악하는 대화형 질의 정규화와 대화형 질의를 검색형 질의로 변경하는 검색 질의 정규화로 나뉨
    - 아래 그림 1과 그림 2는 각 데이터들의 예시   
    ![image](https://user-images.githubusercontent.com/49019292/209498473-35e23f51-9fc5-48c4-9a22-9908771fa3e5.png)   
    - 대화형 질의 정규화는 사용자와 클로바 간의 대화 문맥을 고려하여 마지막 사용자 발화가 이전 문맥과 관련이 있는 발화인지, 문맥과 관련 있는 발화인 경우 문맥에서 필요한 단어, 즉 슬롯 혹은 인텐트들을 현재 발화와 재조합하여 정규화된 응답을 생성하도록 학습
      - 문맥과 관련 없는 발화는 사용자의 마지막 발화와 동일하게 응답을 생성하도록 학습 
  - P-tuning
    - 기존 초거대모델을 활용한 few-shot 학습법은 탬플릿을 어떻게 구성하느냐에 따라 성능이 차이남
    - 그러나 P-tuning은 추가 토큰을 정의하고 데이터에 기반하여 추가 토큰을 연속 공간에서 학습하므로 태스크에 대해 초거대 모델이 가지는 지식을 충분히 활용할 수 있음
    - P-tuning 학습을 위해 아래 그림 3과 같이 프롬프트 인코더와 기학습된 언어모델이 요구됨(구조)   
    ![image](https://user-images.githubusercontent.com/49019292/209498491-a266e585-2501-43b5-98cb-3f4dbdd2403d.png)  
  - 기학습된 언어 모델
    - 네이버의 HyperClova 사용(본 논문에서는 1.3B, 6.7B, 13B, 39B parameter 갯수를 갖는 4개의 모델)
      - 5,600억개의 토큰 데이터, BBPE 토크나이저 사용
      - BBPE 토크나이저로 토큰화된 T개의 연속된 토큰들 x에 대해 다음과 같은 확률 분포를 따름   
      ![image](https://user-images.githubusercontent.com/49019292/209498504-9f577c36-752b-4944-a124-2ddf3d150cce.png)   
  - 프롬프트 인코더
    - 프롬프트 인코더는 템플릿에 정의된 n개의 프롬프트 토큰 p에 대해 다음과 같은 수식을 가짐   
    ![image](https://user-images.githubusercontent.com/49019292/209498513-65020d9d-80dc-48b2-bb41-17b666084a34.png)   
    - 활성화 함수로는 ReLU 사용
  - 학습 방법      
    - 입력값 x와 프롬프트 인코더로부터 추출된 벡터 h를 정의된 P-tuning용 탬플릿에 매핑하여 입력을 정의
    - 이와 짝을 이루는 K개의 응답 토큰 y에 대해 다음과 같은 목적함수를 가짐   
    ![image](https://user-images.githubusercontent.com/49019292/209498532-44ef874a-2fad-4af7-8dc3-cf87ac2105b9.png)  
 -----------------------------------------------
- **실험 및 결과**
  - 데이터
    - 대화형 질의 정규화  
      - 사용자와 클로바 간의 대화를 여러 턴으로 구성하여 직접 데이터를 구축
      - 학습 셋으로는 4,009건, 테스트셋으로 1,142건 활용
      - 학습 셋의 경우 문맥 단절 발화는 전체 발화의 약 10%로 구성
      - 대화 구성은 메모리 부족 문제로 인해 최대 직전 6턴, 최대 길이는 BBPE 토큰 기준 1024 미만으로 제한
    - 검색 질의 정규화
      - 네이버 상위 검색 질의 및 연관 검색어로부터 추출
      - 학습셋은 4322건, 테스트셋은 735건 활용
      - 데이터는 단일 발화와 다중 발화로 구성되어 있음
        - 단일 발화: 대화형 쿼리, 검색형 쿼리
        - 다중 발화: 이전 대화형 쿼리, 현재 대화형 쿼리, 검색형 쿼리
      - 데이터의 최대 길이는 1024 미만으로 제한
  - 실험 구성
    - 프롬프트 구성은 고정 퓨샷을 기준으로 가장 성능이 높은 퓨샷을 탐색 및 고정한 후 프롬프트 토큰을 추가로 배치하고 P-tuning을 통해 학습했을 때 가장 성능이 좋은 경우를 사용하였음
    - 아래 그림은 각 실험에서 최종 프롬프트 구성을 보여줌   
    ![image](https://user-images.githubusercontent.com/49019292/209498551-90be569d-b333-43f3-9c00-186cc88b661a.png)   
    - 프롬프트 인코더의 P-tuning 학습 시 학습률은 1e-5, 배치 사이즈는 2, 프롬프트 인코더의 hidden size는 HyperClova의 각 hidden size와 동일하게 셋팅
    - 평가 척도로는 BLEU 점수와 수동 평가한 정확도 점수 사용
      - 정확도는 대화 질의 정규화의 경우 생성된 정규화 문장에 최종 의도가 정확히 반영되었는지 수동으로 태깅한 값
      - 검색 질의 정규와의 경우 대화형 질의가 검색형 질의로 잘 변환되었는가를 수동으로 태깅한 값
  - 실험 결과
    - 대화형 질의 정규화 결과
      - 아래 표 1은 고정 퓨샷과 P-tuning간의 성능 차이를 검증하기 위해 13B와 39B에서의 BLEU 점수를 각각 산출한 결과   
      ![image](https://user-images.githubusercontent.com/49019292/209498582-ef76456f-c747-414a-ae57-e6761551c421.png)   
      - 아래 표 2는 에폭 별 정확도에 대한 실험 결과   
      ![image](https://user-images.githubusercontent.com/49019292/209498592-e2717cdc-ab81-498a-b96e-c87745a48b42.png)   
      - 20 에폭에서 가장 정확도가 높았고 이보다 더 학습을 진행한 경우 컨텍스트의 과한 연결로 오답이 되는 사례가 증가하였음(아래 그림 5)   
      ![image](https://user-images.githubusercontent.com/49019292/209498600-5fc74ea6-6591-43dc-97cb-71d310d57d54.png)   
      - 아래 표 3은 모델 크기별 성능   
      ![image](https://user-images.githubusercontent.com/49019292/209498610-3b119a8b-6141-47ba-a0f9-7f9e97329d01.png)   
    - 검색 질의 정규화 결과
      - 실험한 모델 중 가장 성능이 좋고서비스에 적용하기 속도, 정확도 트레이드 오프 간 가장 좋다고 판단한 6.7B 모델에 대해서 실험함
      - 아래 표 4는 실험 결과   
      ![image](https://user-images.githubusercontent.com/49019292/209498623-bd7f5c12-dd2f-4718-89f1-776bcdcbfb0a.png)    
-------------------------------------------------
- **고찰**
  - 한글로 읽는 논문이 이해가 훨씬 쉽다...
    - 굳이 이해만 놓고 보지 않더라도, 문장을 뜯어보고 여러 방향으로 해석할 수 있는 여지가 더 많아서 더 재밌게 읽히는 것 같다.  
  - 다른 논문에서도 P-tuning과 퓨샷 러닝을 많이 비교 하는 것 같다. 
  - 확실히 기업 단에서 작성된 논문이다보니까, 신기한 데이터셋이 더러 보인다.
    - 검색 질의 정규화를 위한 데이터셋만 봐도, 네이버 포털에서 가장 많이 검색된 질의들을 대화형 질의로 transform하여 데이터로 사용하였다.
    - 대기업 좋다..
  - 그래도 한글 데이터라 그런지, 양 자체는 많지 않았다.
    - 많아도 4000건 정도..?
  - 최종 발화에 모든 슬롯 및 인텐트 정보를 담고 있다는 문장이 있는데, 그럼 추출된 인텐트를 슬롯에 담는건가..?
    - 아니면 문장에서 인텐트에 해당하는 위치가 슬롯에 담겨있는건가?
    - 정확한 구성을 모르겠다 :sob:
