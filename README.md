# Papers that we read

> 모든 구성원들은 적어도 매주 적어도 한 편의 논문을 읽고 리뷰

이 레포지토리는  논문 리뷰를 더 쉽게 찾을 수 있도록 만들어졌습니다.

템플릿: `[Paper Title][Conf or Journal, Year]`

--------------

### General NLP

- [Character-level Convolutional Networks for Text Classification[NIPS2015]](https://github.com/DAILAB-CBNU/Papers/blob/main/General_NLP/Character-level%20Convolutional%20Networks%20for%20Text%20Classification.md)

- [Convolutional Neural Networks for Sentence Classification[EMNLP2014]](https://github.com/DAILAB-CBNU/Papers/blob/main/General_NLP/Convolutional%20Neural%20Networks%20for%20Sentence%20Classification.md)

### Language Model

- TBD

### Natural Language Understanding

- [GPT Understands, Too[arxiv:2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Natural_Language_Understanding/GPT%20Understands%2C%20Too.md)

### Neural Network

- [Deep Learning[Nature2015]](https://github.com/DAILAB-CBNU/Papers/blob/main/Neural_Network/Deep_Learning.md)

### Personality Prediction

- [Text based personality prediction from multiple social media data sources using pre‑trained language model and model averaging[JBD2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Personlity_Prediction/Text%20based%20personality%20prediction%20from%20multiple%20social%20media%20data%20sources%20using%20pre%E2%80%91trained%20language%20model%20and%20model%20averaging.md)

### Text Generation

- [Multiturn dialogue generation by modeling sentence-level and discourse-level contexts[nature scientific report 2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Multiturn%20dialogue%20generation.md)

- [Instance-wise Prompt Tuning for Pretrained Language Models[arxiv:2022]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Instance-wise%20Prompt%20Tuning%20for%20Pretrained%20Language%20Models.md)

- [Large Pre-trained Language Model의 P-tuning을 이용한 질의 정규화[제33회 한글 및 한국어 정보처리 학술대회 논문집 2021]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Generation/Large%20Pre-trained%20Language%20Model%EC%9D%98%20P-tuning%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%A7%88%EC%9D%98%20%EC%A0%95%EA%B7%9C%ED%99%94.md)


### Text Style Transfer

- [Story-level Text Style Transfer: A Proposal[ACL2020]](https://github.com/DAILAB-CBNU/Papers/blob/main/Text_Style_Transfer/Story-level%20Text%20Style%20Transfer:%20A%20Proposal.md)

### Tokenization

- [SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing[EMNLP2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Tokenization/SentencePiece.md)

- [Neural Machine Translation of Rare Words with Subword Units[ACL2016]](https://github.com/DAILAB-CBNU/Papers/blob/main/Tokenization/BPE.md)

- [Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates[ACL2018]](https://github.com/DAILAB-CBNU/Papers/blob/main/Tokenization/Subword%20Regularization.md)

### Word Embedding

- TBD

-----------

### Member

- JunHa-Hwang, hwang_junha@naver.com, ChungBuk National Univ(Undergraduate).
- SeungDong-Lee, sdlee130@naver.com, ChungBuk National Univ(Undergraduate).
- EunJin-Kim, dw0815@chungbuk.ac.kr, ChungBuk National Univ(Bachelor, Graduate)
